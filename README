PROPOSTA DO TRABALHO FINAL DE PROGRAMAÇÃO PARALELA AVANÇADA 
ALUNOS: 
FELIPE DE SOUZA SANT'ANNA SILVEIRA
NATHÁLIA GRAMS TEIXEIRA


ESTE TRABALHO CALCULA INDICADORES SOBRE OS PREÇOS DOS FECHAMENTOS DA EMPRESAS DO S&P 500
 UTILIZANDO MPI, OPENMP E CUDA 
ATUALMENTE ESTÁ IMPLEMENTADO:
-RSI (INDICE DE FORÇA RELATIVA)
-SMA (MÉDIA MÓVEL SIMPLES)
-EMA (MÉDIA MÓVEL EXPONENCIAL)
-STOCHASTIC K (ÍNDICE DE MOMENTO ESTOCÁSTICO K)
-STOCHASTIC D (ÍNDICE DE MOMENTO ESTOCÁSTICO D)
A pasta empresas contém os datasets de cada empresa, que foram divididos através do script split_dataset.py,
e a pasta saida contém os resultados dos cálculos, que são salvos em arquivos CSV.
Para fins de comparação há uma versão sequencial, uma versão com OpenMP e uma versão com CUDA, além da versão paralela com MPI.
A VERSÃO SEQUENCIAL ESTÁ EM sequencial.c : compilar com gcc -o seq sequencial.c
A VERSÃO COM OPENMP ESTÁ EM openmppuro.c : compilar com gcc -o openmp_exec openmppuro.c -fopenmp
A VERSÃO COM CUDA SEQUENCIAL ESTÁ EM cudapuro.cu
nvcc -o cudapuro cudapuro.cu 
A VERSÃO COM CUDA EM LOTE ESTÁ EM cudabatch.cu
nvcc -o cudabatch cudabatch.cu
TESTADO COM UMA GEFORCE GTX 750 Ti, necessário usar nvcc -arch=sm_50

A VERSÃO PARALELA COM MPI ESTÁ EM mpipuro.c
mpicc -o mpi_exec mpipuro.c
para rodar a versão paralela com MPI, é necessário ter o OpenMPI instalado e rodar o comando:
mpirun -np 4 ./mpi_exec
o arquivo hosts.txt pode ser alterado para rodar o mpi acima.


O TAMANHO DA JANELA É DE 14 PERÍODOS, MAS PODE SER ALTERADO EM main.c NA LINHA 
   int window = 14;
A EXECUÇÃO PADRÃO USA 4 PROCESSOS MPI, AINDA NÃO FOI TESTADA COM OUTROS VALORES

IMPORTANTE: O MAKEFILE CONTEM O CAMINHO PARA ONDE ESTA A BIBLIOTECA RUNTIME DO CUDA, 
PARA QUE RODASSE COM A INSTALAÇÃO PADRÃO DO CUDA NA
DISTRIBUIÇÃO ARCH LINUX, ALTERE SE NECESSÁRIO, NAS LINHAS
CUDA_INC = -I/opt/cuda/include
CUDA_LIB = -L/opt/cuda/targets/x86_64-linux/lib -lcudart

Para rodar:
chmod +x test.sh
./test.sh

## COMO OS DATASETS FORAM CRIADOS ##
foi baixado o dataset do kaggle com registros de 5 anos;
https://www.kaggle.com/datasets/iveeaten3223times/massive-yahoo-finance-dataset
foi dividido em datasets para cada empresa na pasta empresas, através do script 
split_dataset.py, excluindo as colunas após a coluna Close;
 
#RESULTADOS PRELIMINARES (i5 10400f + GTX 750 Ti)

sequencial: 0.124095 segundos
openmp: 0.018099 segundos
cuda sequencial: 0.050887 segundos
cuda batch: 0.021721 segundos
mpi: 0.129614 segundos

#RESULTADO PRELIMINAR USANDO OPENCL (GPU MALI-G68 MP5 - 5 NÚCLEOS Samsung A35)

opencl tempo de cálculo indicadores na GPU: 0.506178 s
#INSTRUCOES PARA UTILIZAR A GPU NUM CELULAR ANDROID:
1 - Instalar uma versao recente do Termux (emulador de terminal)
pkg update 
pkg install clang opencl opencl-headers
2 - Copiar as bibliotecas da GPU do sistema  para o path das bibliotecas do Termux
cp /vendor/lib64/libOpenCL.so $PREFIX/lib/
cp /vendor/lib64/libion_exynos.so $PREFIX/lib/
cp /vendor/lib64/libGLES_mali.so $PREFIX/lib/
3 - Compilar com CLang
clang opencl.c -o gpu_calc -lOpenCL -O3
4 - Executar declarando o local para as bibliotecas
LD_LIBRARY_PATH=$PREFIX/lib ./gpu_calc
##TODO-LIST##
Verificar o por quê de a versão sequencial ser mais rápida que a versão OpenMP e MPI;
